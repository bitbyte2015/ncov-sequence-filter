Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 6
Rules claiming more threads will be scaled down.
Job stats:
job                  count    min threads    max threads
-----------------  -------  -------------  -------------
build                    1              1              1
eliminate_spaces         1              1              1
isolate_sequences        1              1              1
nextalign                1              1              1
nextclade                1              1              1
prediction               1              1              1
unpack_gisaid_tar        1              1              1
total                    7              1              1

Select jobs to execute...

[Wed May 18 04:01:42 2022]
rule unpack_gisaid_tar:
    input: data/gisaid_auspice_input_hcov-19_2022_05_18_08(1).tar
    output: data/gisaid.fasta, data/metadata.tsv
    jobid: 6
    resources: tmpdir=/tmp

[Wed May 18 04:01:42 2022]
Error in rule unpack_gisaid_tar:
    jobid: 6
    output: data/gisaid.fasta, data/metadata.tsv
    shell:
        
        tar -xvf data/gisaid_auspice_input_hcov-19_2022_05_18_08(1).tar -C data/unpacked
        mv data/unpacked/*metadata.tsv data/metadata.tsv
        mv data/unpacked/*.fasta data/gisaid.fasta
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2022-05-18T040142.474154.snakemake.log
